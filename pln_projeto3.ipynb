{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import reuters\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escolher um corpus e separar ele em sentencas formadas por tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus():\n",
    "    docs = []\n",
    "    for fileid in reuters.fileids():\n",
    "        docs.append(list(reuters.sents(fileid)))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_corpus()\n",
    "all_sents = [doc[0] for doc in docs]\n",
    "\n",
    "with open('sentences.txt', 'w', encoding='utf8') as file:\n",
    "    for sentence in all_sents:\n",
    "        text_line = \" \".join(sentence)\n",
    "        file.write(f'{text_line}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vetorizar as sentenças do documento. Teste as várias opções de vetorização que aprendemos (TF-IDF, Doc2Vec, LDA, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de sentenca com os tokens (palavras) separados, que foi usado para treinar o modelo e que vai ser vetorizado na etapa seguinte:\n",
      "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n",
      "\n",
      "\n",
      "Exemplo de vetorizacao da sentenca acima, com 200 dimensoes:\n",
      "[-5.42353955e-04  4.12977226e-02  4.10420373e-02 -5.72566539e-02\n",
      "  1.46874199e-02 -2.35935976e-03  1.89877935e-02 -5.65520488e-02\n",
      "  4.29281127e-03  4.94865440e-02 -3.71050760e-02  1.27204768e-02\n",
      "  6.31043501e-03  8.26270133e-02  2.16809213e-02 -6.83984580e-03\n",
      "  1.26413424e-02  2.04773583e-02  3.07334363e-02  3.05679794e-02\n",
      " -5.86936139e-02 -3.92802991e-02  3.80552411e-02 -6.67240750e-03\n",
      "  2.58056028e-03 -1.25163849e-02 -3.38785984e-02 -1.62127952e-03\n",
      "  3.50614414e-02 -1.74811911e-02 -7.22165480e-02  8.79778434e-03\n",
      " -1.96419526e-02  6.19507916e-02  1.42375389e-02 -3.51821333e-02\n",
      " -3.11034899e-02  2.85365153e-03  7.48481601e-02  4.68230173e-02\n",
      "  4.03954461e-02  4.03279327e-02 -3.11169457e-02  4.48898561e-02\n",
      " -3.12810130e-02  5.38113564e-02  1.02490177e-02  2.30594948e-02\n",
      " -5.26282787e-02 -4.06491458e-02 -3.62313949e-02  6.02593422e-02\n",
      "  5.78266419e-02  1.62138604e-02  6.43640291e-03  1.87772289e-02\n",
      " -3.13424394e-02 -2.47616097e-02  7.61556905e-03 -1.58879906e-03\n",
      " -1.43700819e-02  1.27844103e-02 -1.82748996e-02  1.46186193e-02\n",
      " -3.53932828e-02  2.36097947e-02 -4.97751720e-02  4.52001654e-02\n",
      "  1.64183974e-02  6.92541376e-02  3.49750137e-03 -7.92422332e-03\n",
      "  2.30015088e-02  5.66673465e-04  1.11123677e-02  2.56809895e-03\n",
      "  2.18373984e-02 -2.45364401e-02  2.42234617e-02  6.16521463e-02\n",
      " -6.36354275e-03  2.48676427e-02  1.44565366e-02 -4.25863527e-02\n",
      " -8.98633152e-06 -3.28955948e-02 -6.90043671e-03  9.59554687e-02\n",
      "  7.06504136e-02 -1.90984663e-02 -1.88306328e-02  5.30897193e-02\n",
      "  6.94978833e-02  4.40525115e-02 -5.24000935e-02  1.89663749e-02\n",
      "  2.78836116e-02  4.15054057e-03 -2.90383492e-02 -3.12010758e-02\n",
      "  4.57799844e-02 -3.45192403e-02  4.11349647e-02 -8.65027495e-03\n",
      " -5.51001430e-02  3.07598859e-02 -7.29074404e-02  1.03648240e-02\n",
      "  9.99344699e-03 -3.33543424e-03  2.73519065e-02 -3.08108963e-02\n",
      "  7.56209940e-02 -9.20377020e-03 -3.61288674e-02 -1.75478645e-02\n",
      "  1.52227599e-02  1.49082541e-02  3.37518305e-02  5.88022247e-02\n",
      "  2.71141455e-02 -2.19712756e-03 -3.30056511e-02  6.54422026e-03\n",
      " -1.18356079e-01  2.71563325e-02 -2.42260043e-02 -9.06111207e-03\n",
      "  2.58185472e-02  2.10433081e-02 -4.74079810e-02  2.78530968e-03\n",
      "  9.40755662e-03 -1.61708239e-02  3.41342539e-02 -6.76201843e-03\n",
      "  4.76487540e-03  1.95025932e-02  1.23384641e-02  8.16238821e-02\n",
      " -1.20672202e-02  6.37732223e-02 -6.59024110e-03 -1.76216178e-02\n",
      " -1.26349824e-02 -3.84747982e-02 -2.66766381e-02 -3.13864276e-02\n",
      "  2.21932977e-02 -5.67209348e-02 -3.41330133e-02 -4.78896964e-03\n",
      "  5.53525500e-02  2.33740658e-02 -3.75138931e-02  8.31128564e-03\n",
      " -4.48430665e-02  3.55608687e-02 -3.60072628e-02 -1.38330255e-02\n",
      "  3.98935415e-02  1.78680588e-02 -3.82530987e-02 -1.59150511e-02\n",
      "  4.77086008e-02  4.36544232e-03 -2.69440264e-02 -7.27512762e-02\n",
      "  2.84097716e-03  4.79930602e-02 -1.31252976e-02 -4.11790162e-02\n",
      "  8.89017899e-03  1.03177165e-03  2.86645833e-02  3.70291546e-02\n",
      " -3.20201255e-02 -6.44268617e-02  2.48566419e-02  2.11443193e-03\n",
      " -4.33706306e-03 -5.41206356e-03 -5.30956779e-04 -3.56655568e-02\n",
      " -6.59119245e-03 -3.97394486e-02  3.07025462e-02  1.77377090e-02\n",
      "  4.43996675e-03  8.03489238e-05 -2.46119909e-02  9.02942121e-02\n",
      " -1.63199250e-02  3.69554535e-02  7.29559362e-02 -2.83149239e-02\n",
      "  6.58344617e-03 -2.70591527e-02  5.65542541e-02  4.20770124e-02]\n",
      "CPU times: user 2min 11s, sys: 1.26 s, total: 2min 12s\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Criando o modelo\n",
    "model = gensim.models.Doc2Vec(\n",
    "    corpus_file='sentences.txt',\n",
    "    vector_size=200,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=8,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Formatando entrada para o modelo e inserindo-a no modelo\n",
    "tld = TaggedLineDocument(\"sentences.txt\")\n",
    "model.train(tld, total_examples=model.corpus_count, epochs=1)\n",
    "\n",
    "# Criando o vetor de tokens\n",
    "sents = []\n",
    "with open('sentences{}.txt'.format(0), 'w', encoding='utf8') as file:\n",
    "    for sentence in docs[0]:\n",
    "        sents.append(sentence)\n",
    "print(\"Exemplo de sentenca com os tokens (palavras) separados, que foi usado para treinar o modelo e que vai ser vetorizado na etapa seguinte:\")\n",
    "print(sents[0])\n",
    "        \n",
    "vetorzao = []\n",
    "for i in sents:\n",
    "    vector = model.infer_vector(i)\n",
    "    vetorzao.append(vector)\n",
    "print(\"\\n\\nExemplo de vetorizacao da sentenca acima, com 200 dimensoes:\")\n",
    "print(vetorzao[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agrupar as sentenças do documento em clusters usando K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia de cada sentenca a cada cluster, respectivamente:\n",
      "[[4.18972918e-01 9.43791263e-01 1.16219615e+00 6.08483492e-01\n",
      "  7.53776051e-01 1.03997684e+00]\n",
      " [9.09257071e-01 6.76677163e-01 1.62850313e+00 7.91070367e-01\n",
      "  1.26591256e+00 1.04170832e+00]\n",
      " [6.45877696e-01 6.31479938e-01 1.31975458e+00 5.00145022e-01\n",
      "  1.02801770e+00 9.83478731e-01]\n",
      " [1.02337094e+00 1.44240993e+00 3.65002415e-08 1.14167648e+00\n",
      "  1.28812172e+00 1.37766441e+00]\n",
      " [8.37920020e-01 3.73051431e-01 1.42816536e+00 5.72514079e-01\n",
      "  1.13763354e+00 8.04945473e-01]]\n",
      "\n",
      "\n",
      "Qual 'categoria' se encaixa cada sentenca, qual o indice do cluster mais proximo da sentenca:\n",
      "[0 1 3 2 1]\n",
      "\n",
      "\n",
      "Com o indice do cluster mais proximo de cada sentenca, é possivel relacionar a distancia dessa sentenca ao seu cluster mais proximo, assim resultando na lista de sentencas mais proximas de seus clusters mais proximos a seguir:\n",
      "[0.41897291775203066, 0.6766771630009544, 0.5001450221680627, 3.650024149988857e-08, 0.37305143097197735]\n",
      "CPU times: user 68.4 ms, sys: 1 µs, total: 68.4 ms\n",
      "Wall time: 67.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_ = KMeans(n_clusters=6, random_state=42)\n",
    "result = kmeans_.fit_transform(vetorzao)\n",
    "print(\"Distancia de cada sentenca a cada cluster, respectivamente:\")\n",
    "print(result[0:5])\n",
    "res = kmeans_.fit_predict(vetorzao)\n",
    "print(\"\\n\\nQual 'categoria' se encaixa cada sentenca, qual o indice do cluster mais proximo da sentenca:\")\n",
    "print(res[0:5])\n",
    "lista = [result[x][res[x]] for x in range(len(res))]\n",
    "print(\"\\n\\nCom o indice do cluster mais proximo de cada sentenca, é possivel relacionar a distancia dessa sentenca ao seu cluster mais proximo, assim resultando na lista de sentencas mais proximas de seus clusters mais proximos a seguir:\")\n",
    "print(lista[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Escolher as sentenças mais próximas do centro do cluster, para cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escolhemos as 5 sentencas com a menor distancia a um cluster, assim assegurando que estas são as que melhor resumem o documento dado este modelo. Mesmo que duas sentencas pertencam a assuntos, ou clusteres, diferentes, se pegarmos as 5 com menor distancia, temos as 5 que melhor se relacionam a 5 dos 6 clusteres do modelo; descartando um dos clusteres, que nenhuma sentenca chegou tão perto.\n",
      "\n",
      "[0, 2, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "for i in range(5):\n",
    "    val = min(lista)\n",
    "#     print(val)\n",
    "    final_list.append(lista.index(val))\n",
    "    del lista[lista.index(val)]\n",
    "\n",
    "print(\"Escolhemos as 5 sentencas com a menor distancia a um cluster, assim assegurando que estas são as que melhor resumem o documento dado este modelo. Mesmo que duas sentencas pertencam a assuntos, ou clusteres, diferentes, se pegarmos as 5 com menor distancia, temos as 5 que melhor se relacionam a 5 dos 6 clusteres do modelo; descartando um dos clusteres, que nenhuma sentenca chegou tão perto.\")\n",
    "print()\n",
    "print(sorted(final_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exibir estas sentenças na ordem em que se apresentaram no texto original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com as sentencas mais proximas dos clusteres listadas, faltou só ordena-las na ordem em que aparecem no documento original e assim é possivel resumir o texto original grosseiramente nas suas sentencas mais importantes, como vemos no paragrafo a seguir:\n",
      "\n",
      "ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said . But some exporters said that while the conflict would hurt them in the long - run , in the short - term Tokyo ' s loss might be their gain . Taiwan had a trade trade surplus of 15 . 6 billion dlrs last year , 95 pct of it with the U . S . The surplus helped swell Taiwan ' s foreign exchange reserves to 53 billion dlrs , among the world ' s largest . \" We must quickly open our markets , remove trade barriers and cut import tariffs to allow imports of U . S . Products , if we want to defuse problems from possible U . S .\n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for index in sorted(final_list):\n",
    "    summary.append(\" \".join(sents[index]))\n",
    "\n",
    "print(\"Com as sentencas mais proximas dos clusteres listadas, faltou só ordena-las na ordem em que aparecem no documento original e assim é possivel resumir o texto original grosseiramente nas suas sentencas mais importantes, como vemos no paragrafo a seguir:\")\n",
    "print()\n",
    "print(\" \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln",
   "language": "python",
   "name": "pln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
